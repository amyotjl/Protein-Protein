{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from statistics import mean\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import itertools\n",
    "import joblib\n",
    "from matplotlib import pyplot as plot\n",
    "import os\n",
    "import gc\n",
    "from load_dataset import get_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels, max_seq_length, input_dim):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.num_conv_layers = len(in_channels)\n",
    "        self.max_seq_length = max_seq_length\n",
    "        unique_aa = 21\n",
    "        # Convolutional layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        in_channels = [1, *in_channels]  # Input channel for the first layer\n",
    "        self.conv_out_height, self.conv_out_width = input_dim\n",
    "\n",
    "        for i in range(self.num_conv_layers):\n",
    "            self.layers.append(nn.Conv2d(in_channels[i], in_channels[i+1], kernel_size=2, stride=1, padding=1))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            self.conv_out_height = self.compute_dim(self.conv_out_height, 2, 1, 1,2, 2)\n",
    "            self.conv_out_width = self.compute_dim(self.conv_out_width, 2, 1, 1,2, 2)\n",
    "        self.conv_net = nn.Sequential(*self.layers)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(int(in_channels[-1] * self.conv_out_height * self.conv_out_width), max_seq_length* unique_aa)\n",
    "    def forward(self, x):\n",
    "        # Reshape the input to match the expected input shape (batch_size, channels, height, width)\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension (batch_size, 1, height, width)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = self.conv_net(x)\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    def compute_dim(self, dim, conv_k, conv_s, conv_p, pool_k, pool_s):\n",
    "        dim = np.floor(((dim - conv_k + 2 *conv_p)/conv_s)+1)\n",
    "        return np.floor(((dim - pool_k)/pool_s)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device('cpu') \n",
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_dataloader('Prots_embeddings_mat.joblib', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(conv_net, train_loader, test_loader, optimizer:optim, epochs:int = 10, batch_size:int = 64, loss_fn =nn.MSELoss()):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print('epoch {}'.format(i))\n",
    "        epoch_loss = []\n",
    "        test_loss = []\n",
    "\n",
    "        # Training\n",
    "        for _, (batch,labels) in tqdm(enumerate(train_loader), total=np.ceil(len(train_loader)/batch_size)):\n",
    "            conv_net.zero_grad()\n",
    "            # print(type(batch), batch.shape)\n",
    "            batch = batch.to(gpu)\n",
    "            labels = labels.view(len(batch), -1).to(gpu)\n",
    "            \n",
    "            output = conv_net(batch)\n",
    "            loss_train = loss_fn(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss_train.item())\n",
    "\n",
    "        # Test Set\n",
    "        for _, (batch,labels) in enumerate(test_loader):\n",
    "            conv_net.zero_grad()\n",
    "            batch = batch.to(gpu)\n",
    "            labels = labels.view(len(batch), -1).to(gpu)\n",
    "\n",
    "            output = conv_net(batch)\n",
    "            loss_test = loss_fn(output, labels)\n",
    "            test_loss.append(loss_test.item())\n",
    "\n",
    "        train_losses.append(np.average(epoch_loss))\n",
    "        test_losses.append(np.average(test_loss))\n",
    "    return train_losses, test_losses\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(4,300,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ''\n",
    "del net \n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [4,8]  # Define the number of convolutional layers\n",
    "net = ConvNet(conv_layers, 1965, data.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adagrad(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(net, train_loader, test_loader, optimizer, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
