{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from statistics import mean\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import itertools\n",
    "import joblib\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jean-Luc\\.conda\\envs\\protein-protein\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "#loading file\n",
    "amino_acid_df = pd.read_excel(\"data/AminoAcid.xlsx\", header=None)\n",
    "amino_acid_df.columns = ['protein', 'sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1EP9_1</td>\n",
       "      <td>VQLKGRDLLTLKNFTGEEIKYMLWLSADLKFRIKQKGEYLPLLQGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1BH9_1</td>\n",
       "      <td>LFSKELRCMMYGFGDDQNPYTESVDILEDLVIEFITEMTHKAMSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1G96_1</td>\n",
       "      <td>VGGPMDASVEEEGVRRALDFAVGEYNKASNDMYHSRALQVVRARKQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CYV_1</td>\n",
       "      <td>MIPGGLSEAKPATPEIQEIVDKVKPQLEEKTNETYGKLEAVQYKTQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1KE5_1</td>\n",
       "      <td>MENFQKVEKIGEGTYGVVYKARNKLTGEVVALKKIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein                                           sequence\n",
       "0  1EP9_1  VQLKGRDLLTLKNFTGEEIKYMLWLSADLKFRIKQKGEYLPLLQGK...\n",
       "1  1BH9_1      LFSKELRCMMYGFGDDQNPYTESVDILEDLVIEFITEMTHKAMSI\n",
       "2  1G96_1  VGGPMDASVEEEGVRRALDFAVGEYNKASNDMYHSRALQVVRARKQ...\n",
       "3  1CYV_1  MIPGGLSEAKPATPEIQEIVDKVKPQLEEKTNETYGKLEAVQYKTQ...\n",
       "4  1KE5_1               MENFQKVEKIGEGTYGVVYKARNKLTGEVVALKKIR"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the sequences in letters\n",
    "amino_acid_df['sequence'] = amino_acid_df['sequence'].apply(lambda seq: list(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1EP9_1</td>\n",
       "      <td>[V, Q, L, K, G, R, D, L, L, T, L, K, N, F, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1BH9_1</td>\n",
       "      <td>[L, F, S, K, E, L, R, C, M, M, Y, G, F, G, D, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1G96_1</td>\n",
       "      <td>[V, G, G, P, M, D, A, S, V, E, E, E, G, V, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CYV_1</td>\n",
       "      <td>[M, I, P, G, G, L, S, E, A, K, P, A, T, P, E, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1KE5_1</td>\n",
       "      <td>[M, E, N, F, Q, K, V, E, K, I, G, E, G, T, Y, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein                                           sequence\n",
       "0  1EP9_1  [V, Q, L, K, G, R, D, L, L, T, L, K, N, F, T, ...\n",
       "1  1BH9_1  [L, F, S, K, E, L, R, C, M, M, Y, G, F, G, D, ...\n",
       "2  1G96_1  [V, G, G, P, M, D, A, S, V, E, E, E, G, V, R, ...\n",
       "3  1CYV_1  [M, I, P, G, G, L, S, E, A, K, P, A, T, P, E, ...\n",
       "4  1KE5_1  [M, E, N, F, Q, K, V, E, K, I, G, E, G, T, Y, ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acid_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding of the amino-acid sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_amino_acid = list(set([item for sublist in amino_acid_df['sequence'] for item in sublist]))\n",
    "unique_amino_acid.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght_amino_acid = len(max(amino_acid_df['sequence'], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to one-hot encode a sequence of amino acid.\n",
    "# The output is a matrix of max_lenght_amino_acid (1965) x unique_amino_acid (21). Sequence shorter than max_lenght_amino_acid are filled with 0. \n",
    "def one_hot_encode(seq):\n",
    "    matrix = np.zeros((max_lenght_amino_acid, len(unique_amino_acid)))\n",
    "    for idx, elem in enumerate(seq):\n",
    "        matrix[idx][unique_amino_acid.index(elem)] = 1\n",
    "    return matrix.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid_df['seq_one_hot'] = amino_acid_df['sequence'].apply(lambda seq: one_hot_encode(seq))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_lin(nn.Module):\n",
    "    def __init__(self, input_shape, layers):\n",
    "        super().__init__()\n",
    "        self.layers = [input_shape, *layers]\n",
    "        self.input_shape = input_shape\n",
    "        # Encoder\n",
    "        encoder_modules = nn.ModuleList()\n",
    "        for idx in range(len(self.layers)-1):\n",
    "            # print('encoder: ',self.layers[idx], self.layers[idx+1])\n",
    "\n",
    "            encoder_modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.layers[idx], self.layers[idx+1]),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "        self.encoder = nn.Sequential(*encoder_modules)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_modules = nn.ModuleList()\n",
    "        for idx in range(len(self.layers)-1):\n",
    "            # print('decoder: ',self.layers[-idx - 1], self.layers[-idx-2])\n",
    "            decoder_modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.layers[-idx-1], self.layers[-idx-2]),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "        self.decoder = nn.Sequential(*decoder_modules)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input = input.reshape(1,-1)\n",
    "        input = self.encoder(input)\n",
    "        input = self.decoder(input)\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid acitvation\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder:AE_lin, data:pd.DataFrame, optimizer:optim, epochs:int = 10, batch_size:int = 64, loss_fn =DiceLoss()):\n",
    "    losses = []\n",
    "    dataloader = DataLoader(data,batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(epochs):\n",
    "        epoch_loss = []\n",
    "        for _, batch in tqdm(enumerate(dataloader), total=np.ceil(len(data)/batch_size)):\n",
    "            autoencoder.zero_grad()\n",
    "            batch = batch.to(gpu)\n",
    "            output = autoencoder(batch)\n",
    "            loss = loss_fn(output, batch).sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "            # print(epoch_loss)\n",
    "        losses.append(np.average(epoch_loss))\n",
    "        print(losses)\n",
    "    return losses\n",
    "batch_size = 64\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 500] Adam MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:10<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:11<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:11<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:11<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [08:46<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:06<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:05<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396, 0.0043058071083471395]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396, 0.0043058071083471395, 0.004305596630130072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396, 0.0043058071083471395, 0.004305596630130072, 0.004305633597130723]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [09:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396, 0.0043058071083471395, 0.004305596630130072, 0.004305633597130723, 0.004305892044281149]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680.0 [08:40<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08587559185381156, 0.004306091548984542, 0.004305369485690094, 0.004306152497541488, 0.004305488946984577, 0.004305572241804946, 0.00430572909912478, 0.0043057851757005074, 0.004305469439200619, 0.0043055267357404396, 0.0043058071083471395, 0.004305596630130072, 0.004305633597130723, 0.004305892044281149, 0.004305332906283986]\n",
      "[5000, 500] Adam DiceLoss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 323/680.0 [04:35<05:04,  1.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer \u001b[39m=\u001b[39m opt(ae\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[0;32m     13\u001b[0m loss_fn \u001b[39m=\u001b[39m loss()\n\u001b[1;32m---> 14\u001b[0m test \u001b[39m=\u001b[39m train(ae, amino_acid_df[\u001b[39m'\u001b[39;49m\u001b[39mseq_one_hot\u001b[39;49m\u001b[39m'\u001b[39;49m], optimizer,epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size, loss_fn\u001b[39m=\u001b[39;49mloss_fn)\n\u001b[0;32m     15\u001b[0m joblib\u001b[39m.\u001b[39mdump({\u001b[39m'\u001b[39m\u001b[39mautoencoder\u001b[39m\u001b[39m'\u001b[39m: ae,\n\u001b[0;32m     16\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m: optimizer,\n\u001b[0;32m     17\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: test,\n\u001b[0;32m     18\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m\"\u001b[39m:layers,\n\u001b[0;32m     19\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mloss_fn\u001b[39m\u001b[39m\"\u001b[39m: loss\n\u001b[0;32m     20\u001b[0m              }, \u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.joblib\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(layers,name,loss_name))\n",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(autoencoder, data, optimizer, epochs, batch_size, loss_fn)\u001b[0m\n\u001b[0;32m     12\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 14\u001b[0m     epoch_loss\u001b[39m.\u001b[39;49mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     15\u001b[0m     \u001b[39m# print(epoch_loss)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m losses\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39maverage(epoch_loss))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# [2000,200], [2000, 500, 200],\n",
    "for layers, (opt,name), (loss,loss_name) in itertools.product([[5000, 500], [10000, 1000]],\n",
    "                                                       [(optim.Adam, 'Adam'), (optim.Adagrad, 'Adagrad')],\n",
    "                                                       [(nn.MSELoss, \"MSE\"), (DiceLoss, 'DiceLoss'), (nn.L1Loss,'L1')]):\n",
    "    print(layers, name, loss_name)\n",
    "    ae = AE_lin(len(unique_amino_acid), layers).to(gpu)\n",
    "    optimizer = opt(ae.parameters(), lr=0.01)\n",
    "    loss_fn = loss()\n",
    "    test = train(ae, amino_acid_df['seq_one_hot'], optimizer,epochs=15, batch_size=batch_size, loss_fn=loss_fn)\n",
    "    joblib.dump({'autoencoder': ae,\n",
    "                 \"optimizer\": optimizer,\n",
    "                 \"loss\": test,\n",
    "                 \"layers\":layers,\n",
    "                 \"loss_fn\": loss\n",
    "                 }, \"models/{}_{}_{}.joblib\".format(layers,name,loss_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
